{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d44aea-08e6-40a6-b42d-87c17902a1d2",
   "metadata": {},
   "source": [
    "## PyTorch Model\n",
    "\n",
    "In this project we will go through the following models:\n",
    "\n",
    "- [Tensor Basics - Create, operation, GPU support](#tensors)\n",
    "- [Autograd - Linear regression model](#autograd)\n",
    "- [Training Loop with: Model, Loss, and Optimizer](#training)\n",
    "- [Neural Network - Datasets, DataLoader, Transforms, and Evaluation](#fneuron)\n",
    "- Convolutional Neural Network - save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaff0196-a706-47e8-a7e3-1fe57cfeeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa96b80-5d7a-481d-9b45-d0e2dd7734f4",
   "metadata": {},
   "source": [
    "<a id='tensors'></a>\n",
    "### Tensor Basics\n",
    "\n",
    "In PyTorch everything is based on tensors, which are multi-dimensional matrices containing the elements of a single data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f502538f-eaf2-4b0d-86da-68605a065dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## empty matrices\n",
    "## which basically grabs random blocks of memory\n",
    "## which we can create scalar\n",
    "sca = torch.empty(1) \n",
    "## or vectors\n",
    "vec = torch.empty(5)\n",
    "## or matrices\n",
    "matr = torch.empty(3, 3)\n",
    "## or multi-dimentional tensors\n",
    "mult = torch.empty(3, 3, 3)\n",
    "## we can aslo create random matrices\n",
    "## very similar to numpy\n",
    "random = torch.rand(2, 3, 4)\n",
    "## or zeros\n",
    "zeros = torch.zeros(3, 4, 5)\n",
    "## or ones\n",
    "ones = torch.ones(2, 2, 3)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10ae3923-2970-4f8c-81fa-a822bfd5f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([2, 2, 3])\n",
      "2\n",
      "torch.float32\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "## we can check the size and shape of the tensors\n",
    "print(zeros.size())\n",
    "print(ones.shape)\n",
    "## and we can simply access the values\n",
    "print(ones.shape[1])\n",
    "## we can also check the data type\n",
    "print(ones.dtype)\n",
    "## by default the type is float32\n",
    "## but we can change it when constructing the tensor\n",
    "tn = torch.rand(2, 3, dtype=torch.float16)\n",
    "print(tn.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38d08cc1-97bf-4677-8285-30aea0969b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int16)\n",
      "tensor([ 0.0000,  0.5791,  1.1582,  1.7373,  2.3164,  2.8945,  3.4746,  4.0508,\n",
      "         4.6328,  5.2109,  5.7891,  6.3672,  6.9492,  7.5273,  8.1016,  8.6875,\n",
      "         9.2656,  9.8438, 10.4219, 11.0000], dtype=torch.float16)\n",
      "tensor([ 0.0000,  0.5789,  1.1579,  1.7368,  2.3158,  2.8947,  3.4737,  4.0526,\n",
      "         4.6316,  5.2105,  5.7895,  6.3684,  6.9474,  7.5263,  8.1053,  8.6842,\n",
      "         9.2632,  9.8421, 10.4211, 11.0000], dtype=torch.float64)\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "0.0\n",
      "torch.Size([4, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2069, 0.4138, 0.6206, 0.8276, 1.0342, 1.2412, 1.4482, 1.6553,\n",
       "        1.8623, 2.0684, 2.2754, 2.4824, 2.6895, 2.8965, 3.1035, 3.3105, 3.5176,\n",
       "        3.7246, 3.9316, 4.1367, 4.3438, 4.5508, 4.7578, 4.9648, 5.1719, 5.3789,\n",
       "        5.5859, 5.7930, 6.0000], dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we can also create tensors from list or arrays\n",
    "lst = range(11)\n",
    "tnfls = torch.tensor(lst, dtype = torch.int16)\n",
    "print(tnfls)\n",
    "arr = np.linspace(0, 11, 20)\n",
    "## this will create a copy\n",
    "tnfar = torch.tensor(arr, dtype=torch.float16)\n",
    "print(tnfar)\n",
    "## where this way they'll share the same memory\n",
    "tnfarsm = torch.from_numpy(arr)\n",
    "print(tnfarsm)\n",
    "## slicing is similar to np arrays as well\n",
    "print(zeros[:, 1])\n",
    "print(zeros[0, :])\n",
    "## or access one item in specific index\n",
    "print(zeros[0,0, 0].item())\n",
    "## we can also reshape the tensor \n",
    "nten = tnfar.view(4, 5)\n",
    "print(nten.shape)\n",
    "## we can create a np array from a tensor\n",
    "## but we have to be carefull if we're using CPU\n",
    "## because they'll share the same memory loc\n",
    "## and change in one will change the other as well\n",
    "arrftn = tnfar.numpy()\n",
    "## we can aslo have pytorch calculating \n",
    "## the gradient for a tensor\n",
    "## which can be useful when we're optimizing \n",
    "arr2 = np.linspace(0, 6, 30)\n",
    "grtn = torch.tensor(arr2, dtype = torch.float16, requires_grad=True)\n",
    "grtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a439d3a0-1d52-4c54-a457-e0544af70472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4554, 0.7651],\n",
       "        [0.8806, 1.1813]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we can also do all the operations \n",
    "## that we can do with np arrays with tensors\n",
    "rand1 = torch.rand(2, 2)\n",
    "rand2 = torch.rand(2, 2)\n",
    "## we can add them\n",
    "rand3 = torch.add(rand1, rand2)\n",
    "## or use inplace addition\n",
    "## rand1.add_(rand2)\n",
    "## sub\n",
    "rand4 = torch.sub(rand1, rand2)\n",
    "## multiply them\n",
    "rand5 = torch.mul(rand1, rand2)\n",
    "## divide them\n",
    "rand6 = torch.div(rand1, rand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8642f63-7ac8-4117-8c5f-ca80f773179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7207, 0.3691],\n",
      "        [0.3076, 0.2598]], dtype=torch.float16)\n",
      "tensor([[0.3145, 0.5518, 0.7104],\n",
      "        [0.8188, 0.8291, 0.9517],\n",
      "        [0.8564, 0.5396, 0.5063]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "## by default all the tensors are created on CPU\n",
    "## but we can move them into GPU, or create them on GPU directly\n",
    "## we can create a device object\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "## and then pass it when we're creating a tensor\n",
    "## by moving them after creation\n",
    "nwtn = torch.rand(2, 2, dtype=torch.float16).to(device)\n",
    "## or at creation, which is more efficient\n",
    "nwtn2 = torch.rand(3, 3, dtype=torch.float16, device=device)\n",
    "print(nwtn)\n",
    "print(nwtn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfe0b5-bb8e-4c2e-9c78-de280231dbb2",
   "metadata": {},
   "source": [
    "<a id='autograd'></a>\n",
    "### Autograd\n",
    "\n",
    "The autograd package provides automatic differentiation for all operations on tensors; `torch.autograd` is an engine for computing the vector Jacobian product - it computes the partial derivates while applying the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80022364-14cc-4073-b716-19bb2cdd7b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.3333, 0.6665, 1.0000, 1.3330, 1.6670, 2.0000, 2.3340, 2.6660,\n",
      "        3.0000], dtype=torch.float16, requires_grad=True)\n",
      "tensor([5.0000, 5.3320, 5.6680, 6.0000, 6.3320, 6.6680, 7.0000, 7.3359, 7.6641,\n",
      "        8.0000], dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0000,  0.1899,  0.5049,  0.8076,  0.9707,  0.9229,  0.6855,  0.3579,\n",
      "         0.0864, -0.0205], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "tensor(0.4504, dtype=torch.float16, grad_fn=<MeanBackward0>)\n",
      "None\n",
      "tensor([ 0.0284,  0.0815,  0.0999,  0.0753,  0.0188, -0.0463, -0.0911, -0.0969,\n",
      "        -0.0617,  0.0005], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "## we used the requires_grad = True in the section above\n",
    "## and now we can actually see the impact\n",
    "x = torch.linspace(0, 3, 10, requires_grad=True, dtype=torch.float16)\n",
    "y = x + 5\n",
    "print(x)\n",
    "## and we can see that now there's a grad_fn for y\n",
    "## and for this case is AddBackward\n",
    "## which uses the backpropagation\n",
    "print(y)\n",
    "## and we can see if we multiply the tensors\n",
    "## then the gard_fn will change to MulBackward\n",
    "z = torch.sin(x)*torch.cos(y)\n",
    "print(z)\n",
    "## and then to add more layer\n",
    "## if we get the mean then it'll become MeanBackward\n",
    "z = torch.mean(z)\n",
    "print(z)\n",
    "## and we can calculate the gradient \n",
    "## by calling the backward on the variable\n",
    "## and before calling it, there's no grad\n",
    "## for the variable that we're calculating\n",
    "## derivative with respect to\n",
    "print(x.grad)\n",
    "z.backward()\n",
    "## this will contain dz/dx values\n",
    "print(x.grad)\n",
    "## and we have to be carefull while using this \n",
    "## because each time we call backward on a function\n",
    "## the gradients accumulate and if we're looping \n",
    "## for our model training, we have to empty the grad attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc5de0e8-da1c-4627-89c8-2836919c8459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<MulBackward0 object at 0x0000014C280871C0>\n",
      "False\n",
      "tensor([  5.0000,   6.2346,   9.9383,  16.1111,  24.7531,  35.8642,  49.4444,\n",
      "         65.4938,  84.0124, 105.0000])\n",
      "True\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## there are cases where we don't want to track our history\n",
    "## during training when we want to update our weights\n",
    "## or when we're evaluating the model\n",
    "## to prevent the tracking\n",
    "## we can use .required_grad_(False)\n",
    "## or .detach()\n",
    "## or use the torch.no_grad() wrapper\n",
    "a = torch.linspace(0, 10, 10, requires_grad=True)\n",
    "b = a * 5\n",
    "print(a.requires_grad)\n",
    "print(b.grad_fn)\n",
    "## changing it inplace\n",
    "a.requires_grad_(False)\n",
    "c = a**2 + 5\n",
    "print(a.requires_grad)\n",
    "## and now c doesn't have a grad_fn\n",
    "print(c)\n",
    "## if we want to create a copy instead\n",
    "## we can use detach\n",
    "a.requires_grad_(True)\n",
    "d = a.detach()\n",
    "print(a.requires_grad)\n",
    "print(d.requires_grad)\n",
    "## and the 3rd way that's common for evaluation step\n",
    "with torch.no_grad():\n",
    "    e = a ** 2 + 5\n",
    "    print(e.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ef705-5c3a-47d1-8e6a-117333c9262e",
   "metadata": {},
   "source": [
    "#### Gradient Descent by Autograd\n",
    "\n",
    "reminder:\n",
    "$ f(x) =  \\omega \\times x + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fba2c2ce-40a3-4d85-83c6-3fb516c2cc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated loss value 0.0, with w = 4.0, and for testing f(x=3) = 12.0\n"
     ]
    }
   ],
   "source": [
    "## lets create a simple example\n",
    "x = torch.arange(start=0, end=11)\n",
    "y = x * 4\n",
    "## create our initial valuse for w and b\n",
    "## and we need to set the requires_grad to True\n",
    "## and we will use a simple example with no intercept\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "## our main function will be \n",
    "def func(x, w):\n",
    "    return w * x\n",
    "## and then our loss is simply\n",
    "## mean squared errors for y values\n",
    "def loss(yhat, y):\n",
    "    return torch.mean((yhat-y)**2)\n",
    "## and then we can start with training\n",
    "## we also need a learning rate\n",
    "learning_rate = 0.01\n",
    "for _ in range(100):\n",
    "    ## first we calculate yhat\n",
    "    yhat = func(x, w)\n",
    "    ## and then the loss values\n",
    "    l = loss(yhat, y)\n",
    "    ## and all we need to do now is to call\n",
    "    ## backward on loss\n",
    "    l.backward()\n",
    "    ## and then we only have to update w\n",
    "    ## using the gradients\n",
    "    ## and we don't want them to accumulate\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad.data\n",
    "    ## and then after updating the w\n",
    "    ## we will empty the gradients \n",
    "    ## for the next loop\n",
    "    w.grad.data.zero_()\n",
    "    \n",
    "print(f'The calculated loss value {l}, with w = {w.item()}, and for testing f(x=3) = {func(3, w).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65cdf2-3ba0-44e5-a6ad-c34a90daf70f",
   "metadata": {},
   "source": [
    "<a id='training'></a>\n",
    "#### Working with models, loss, and optimizers\n",
    "\n",
    "A PyTorch pipeline is usually like this:\n",
    "\n",
    "    1. Model Design - input, output, forward pass with multiple layers\n",
    "    2. Construct loss and optimizer\n",
    "    3. Training loop\n",
    "        - Forward - computing prediction and loss\n",
    "        - Backward - computing gradients\n",
    "        - Updating the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94471659-833f-40e0-ab83-a3c987c756a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:1.9741042852401733, loss:0.0070242201909422874; f(x=3.0) = 6.102593898773193\n"
     ]
    }
   ],
   "source": [
    "## we will create our own model, by using nn module\n",
    "from torch import nn\n",
    "## and our class should inherit from nn\n",
    "class LinearRegression(nn.Module):\n",
    "    ## and we only need the input and output dimensions\n",
    "    def __init__(self, input_d, output_d):\n",
    "        ## we have to also use super\n",
    "        super(LinearRegression, self).__init__()\n",
    "        ## we have to then create the linear model\n",
    "        self.lin = nn.Linear(input_d,output_d)\n",
    "    ## the next step is to create our forward func\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "## we also need some sample data to use\n",
    "## which we want 10 samples for one featue\n",
    "X = torch.arange(1, 11, dtype=torch.float32).view(10, 1)\n",
    "y = 2 * X \n",
    "## then we have to create an instance of our model\n",
    "## by passing the # of features\n",
    "model = LinearRegression(X.shape[1], X.shape[1])\n",
    "## and then our loss function\n",
    "loss = nn.MSELoss()\n",
    "## and then our optimizer, which we will use \n",
    "## Stochastic Greadient Descent from pytorch\n",
    "## and pass the model parameters and the learning rate\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "## and we have to loop through and update our w\n",
    "for _ in range(200):\n",
    "    ## first we have to calculate our yhat\n",
    "    yhat = model(X)\n",
    "    ## and then calculating the loss\n",
    "    l = loss(y, yhat)\n",
    "    ## and then calculate the gradients\n",
    "    l.backward()\n",
    "    ## and then updating our params\n",
    "    optimizer.step()\n",
    "    ## and finally, zeroing out our \n",
    "    optimizer.zero_grad()\n",
    "## and at the end, we get the calculated values for w and b\n",
    "w, b = model.parameters()\n",
    "print(f'w:{w.item()}, loss:{l}; f(x=3.0) = {model(torch.tensor([3.0])).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b699b-4339-4e5b-bf68-8cc925505f89",
   "metadata": {},
   "source": [
    "<a id='fneuron'></a>\n",
    "\n",
    "### First Neural Net\n",
    "\n",
    "GPU, Datasets, DataLoader, Transforms, Neural Net, Training, and Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7daa2787-ccee-4d5e-a873-f9175b69afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## first the imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## first defining the parameters\n",
    "## the image sizes when flatten\n",
    "input_size = 28*28\n",
    "hidden_size = 500\n",
    "## the size of each batch\n",
    "batch_size = 100\n",
    "## having 10 digit in the class\n",
    "n_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "## creating the train and test datasets\n",
    "train_data = torchvision.datasets.MNIST(root = '../data/',\n",
    "                                      train=True,\n",
    "                                      transform=transforms.ToTensor(),\n",
    "                                      download=True)\n",
    "test_data = torchvision.datasets.MNIST(root='../data/',\n",
    "                                      train=False,\n",
    "                                      transform=transforms.ToTensor())\n",
    "## the we have to create loaders from each set\n",
    "## so we can iterate over the data in an optimized way\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size)\n",
    "\n",
    "## we can simply iterate over each dataloader obj\n",
    "## this will create an iter obj of one batch\n",
    "example_loader = iter(train_loader)\n",
    "## and we can get the features and the labels\n",
    "example_feature, example_label = next(example_loader)\n",
    "\n",
    "## and showing the first 6 example\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(example_feature[i][0], cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c6008875-46a8-4439-826c-8a8d26793293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is :0.20182709395885468\n",
      "The loss is :0.1598643660545349\n",
      "The loss is :0.05118558928370476\n",
      "The loss is :0.05593160539865494\n"
     ]
    }
   ],
   "source": [
    "## now starting with the model\n",
    "## which inherits from the nn module\n",
    "class NeuralNet(nn.Module):\n",
    "    ## we're using the input size, hidden size and the # of classes\n",
    "    def __init__(self, input_size, hidden_size, n_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        ## and we'll be using 3 layers in our class\n",
    "        ## two linear layers\n",
    "        ## and one activation\n",
    "        self.l1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(in_features=hidden_size, out_features=n_classes)\n",
    "        ## the reason we're not using another\n",
    "        ## activation layer at the end is the loss function we're using\n",
    "    ## next we have to define the forward method\n",
    "    def forward(self, x):\n",
    "        out1 = self.l1(x)\n",
    "        out2 = self.relu(out1)\n",
    "        out3 = self.l2(out2)\n",
    "        return out3\n",
    "    \n",
    "## and now we only need to create an instance of model\n",
    "## and pick our loss and optimizers from available one\n",
    "model = NeuralNet(input_size=input_size, hidden_size=hidden_size, n_classes=n_classes)\n",
    "## and sice we're working with a multi-class classification\n",
    "## we're be using the Cross Entropy as our loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "## and for optimizer, we'll using Adam for this mode\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "## now we have to loop through our training set\n",
    "## for the # of epochs we want\n",
    "epochs = 4\n",
    "for _ in range(epochs):\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        ## we first have to claculate the predictions\n",
    "        ## and we have to reshape our images\n",
    "        pred = model(image.reshape(-1, 28*28))\n",
    "        loss = criterion(pred, label)\n",
    "        ## and then we have to call backward on our loss\n",
    "        loss.backward()\n",
    "        ## and then step for our optimizer\n",
    "        optimizer.step()\n",
    "        ## and then zero out the grid for optimizer\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"The loss is :{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "484b6f60-6956-4024-bf52-bd7321a37f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 100 sample, the accuracy is 97.77%\n"
     ]
    }
   ],
   "source": [
    "## now we need to test our model on our test set\n",
    "## and we don't want the gradient for this round\n",
    "with torch.no_grad():\n",
    "    ## getting the # of samples\n",
    "    ## for later calculations\n",
    "    n_sample = len(test_loader)\n",
    "    ## and initiating the # of corret labels with 0\n",
    "    n_correct = 0\n",
    "    \n",
    "    ## and finally looping through the test set\n",
    "    for image, label in test_loader:\n",
    "        output = model(image.reshape(-1, 28*28))\n",
    "        ## and in order to get the indeces\n",
    "        ## we'll be using the torch max \n",
    "        _, pred = torch.max(output, 1)\n",
    "        n_correct += (pred == label).sum().item()\n",
    "    ## and calculating the accuracy\n",
    "    print(f'For the {n_sample} sample, the accuracy is {n_correct/n_sample}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09e7b5-00d8-451d-998f-cb24f4af8fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
