{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d44aea-08e6-40a6-b42d-87c17902a1d2",
   "metadata": {},
   "source": [
    "## PyTorch Model\n",
    "\n",
    "In this project we will go through the following models:\n",
    "\n",
    "- [Tensor Basics - Create, operation, GPU support](#tensors)\n",
    "- [Autograd - Linear regression model](#autograd)\n",
    "- Training Loop with: Model, Loss, and Optimizer\n",
    "- Neural Network - Datasets, DataLoader, Transforms, and Evaluation\n",
    "- Convolutional Neural Network - save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaff0196-a706-47e8-a7e3-1fe57cfeeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa96b80-5d7a-481d-9b45-d0e2dd7734f4",
   "metadata": {},
   "source": [
    "<a id='tensors'></a>\n",
    "### Tensor Basics\n",
    "\n",
    "In PyTorch everything is based on tensors, which are multi-dimensional matrices containing the elements of a single data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f502538f-eaf2-4b0d-86da-68605a065dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## empty matrices\n",
    "## which basically grabs random blocks of memory\n",
    "## which we can create scalar\n",
    "sca = torch.empty(1) \n",
    "## or vectors\n",
    "vec = torch.empty(5)\n",
    "## or matrices\n",
    "matr = torch.empty(3, 3)\n",
    "## or multi-dimentional tensors\n",
    "mult = torch.empty(3, 3, 3)\n",
    "## we can aslo create random matrices\n",
    "## very similar to numpy\n",
    "random = torch.rand(2, 3, 4)\n",
    "## or zeros\n",
    "zeros = torch.zeros(3, 4, 5)\n",
    "## or ones\n",
    "ones = torch.ones(2, 2, 3)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10ae3923-2970-4f8c-81fa-a822bfd5f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([2, 2, 3])\n",
      "2\n",
      "torch.float32\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "## we can check the size and shape of the tensors\n",
    "print(zeros.size())\n",
    "print(ones.shape)\n",
    "## and we can simply access the values\n",
    "print(ones.shape[1])\n",
    "## we can also check the data type\n",
    "print(ones.dtype)\n",
    "## by default the type is float32\n",
    "## but we can change it when constructing the tensor\n",
    "tn = torch.rand(2, 3, dtype=torch.float16)\n",
    "print(tn.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38d08cc1-97bf-4677-8285-30aea0969b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int16)\n",
      "tensor([ 0.0000,  0.5791,  1.1582,  1.7373,  2.3164,  2.8945,  3.4746,  4.0508,\n",
      "         4.6328,  5.2109,  5.7891,  6.3672,  6.9492,  7.5273,  8.1016,  8.6875,\n",
      "         9.2656,  9.8438, 10.4219, 11.0000], dtype=torch.float16)\n",
      "tensor([ 0.0000,  0.5789,  1.1579,  1.7368,  2.3158,  2.8947,  3.4737,  4.0526,\n",
      "         4.6316,  5.2105,  5.7895,  6.3684,  6.9474,  7.5263,  8.1053,  8.6842,\n",
      "         9.2632,  9.8421, 10.4211, 11.0000], dtype=torch.float64)\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "0.0\n",
      "torch.Size([4, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2069, 0.4138, 0.6206, 0.8276, 1.0342, 1.2412, 1.4482, 1.6553,\n",
       "        1.8623, 2.0684, 2.2754, 2.4824, 2.6895, 2.8965, 3.1035, 3.3105, 3.5176,\n",
       "        3.7246, 3.9316, 4.1367, 4.3438, 4.5508, 4.7578, 4.9648, 5.1719, 5.3789,\n",
       "        5.5859, 5.7930, 6.0000], dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we can also create tensors from list or arrays\n",
    "lst = range(11)\n",
    "tnfls = torch.tensor(lst, dtype = torch.int16)\n",
    "print(tnfls)\n",
    "arr = np.linspace(0, 11, 20)\n",
    "## this will create a copy\n",
    "tnfar = torch.tensor(arr, dtype=torch.float16)\n",
    "print(tnfar)\n",
    "## where this way they'll share the same memory\n",
    "tnfarsm = torch.from_numpy(arr)\n",
    "print(tnfarsm)\n",
    "## slicing is similar to np arrays as well\n",
    "print(zeros[:, 1])\n",
    "print(zeros[0, :])\n",
    "## or access one item in specific index\n",
    "print(zeros[0,0, 0].item())\n",
    "## we can also reshape the tensor \n",
    "nten = tnfar.view(4, 5)\n",
    "print(nten.shape)\n",
    "## we can create a np array from a tensor\n",
    "## but we have to be carefull if we're using CPU\n",
    "## because they'll share the same memory loc\n",
    "## and change in one will change the other as well\n",
    "arrftn = tnfar.numpy()\n",
    "## we can aslo have pytorch calculating \n",
    "## the gradient for a tensor\n",
    "## which can be useful when we're optimizing \n",
    "arr2 = np.linspace(0, 6, 30)\n",
    "grtn = torch.tensor(arr2, dtype = torch.float16, requires_grad=True)\n",
    "grtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a439d3a0-1d52-4c54-a457-e0544af70472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4554, 0.7651],\n",
       "        [0.8806, 1.1813]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we can also do all the operations \n",
    "## that we can do with np arrays with tensors\n",
    "rand1 = torch.rand(2, 2)\n",
    "rand2 = torch.rand(2, 2)\n",
    "## we can add them\n",
    "rand3 = torch.add(rand1, rand2)\n",
    "## or use inplace addition\n",
    "## rand1.add_(rand2)\n",
    "## sub\n",
    "rand4 = torch.sub(rand1, rand2)\n",
    "## multiply them\n",
    "rand5 = torch.mul(rand1, rand2)\n",
    "## divide them\n",
    "rand6 = torch.div(rand1, rand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8642f63-7ac8-4117-8c5f-ca80f773179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7207, 0.3691],\n",
      "        [0.3076, 0.2598]], dtype=torch.float16)\n",
      "tensor([[0.3145, 0.5518, 0.7104],\n",
      "        [0.8188, 0.8291, 0.9517],\n",
      "        [0.8564, 0.5396, 0.5063]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "## by default all the tensors are created on CPU\n",
    "## but we can move them into GPU, or create them on GPU directly\n",
    "## we can create a device object\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "## and then pass it when we're creating a tensor\n",
    "## by moving them after creation\n",
    "nwtn = torch.rand(2, 2, dtype=torch.float16).to(device)\n",
    "## or at creation, which is more efficient\n",
    "nwtn2 = torch.rand(3, 3, dtype=torch.float16, device=device)\n",
    "print(nwtn)\n",
    "print(nwtn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfe0b5-bb8e-4c2e-9c78-de280231dbb2",
   "metadata": {},
   "source": [
    "<a id='autograd'></a>\n",
    "### Autograd\n",
    "\n",
    "The autograd package provides automatic differentiation for all operations on tensors; `torch.autograd` is an engine for computing the vector Jacobian product - it computes the partial derivates while applying the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80022364-14cc-4073-b716-19bb2cdd7b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.3333, 0.6665, 1.0000, 1.3330, 1.6670, 2.0000, 2.3340, 2.6660,\n",
      "        3.0000], dtype=torch.float16, requires_grad=True)\n",
      "tensor([5.0000, 5.3320, 5.6680, 6.0000, 6.3320, 6.6680, 7.0000, 7.3359, 7.6641,\n",
      "        8.0000], dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0000,  0.1899,  0.5049,  0.8076,  0.9707,  0.9229,  0.6855,  0.3579,\n",
      "         0.0864, -0.0205], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "tensor(0.4504, dtype=torch.float16, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## we used the requires_grad = True in the section above\n",
    "## and now we can actually see the impact\n",
    "x = torch.linspace(0, 3, 10, requires_grad=True, dtype=torch.float16)\n",
    "y = x + 5\n",
    "print(x)\n",
    "## and we can see that now there's a grad_fn for y\n",
    "## and for this case is AddBackward\n",
    "## which uses the backpropagation\n",
    "print(y)\n",
    "## and we can see if we multiply the tensors\n",
    "## then the gard_fn will change to MulBackward\n",
    "z = torch.sin(x)*torch.cos(y)\n",
    "print(z)\n",
    "## and then to add more layer\n",
    "## if we get the mean then it'll become MeanBackward0\n",
    "z = torch.mean(z)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5de0e8-da1c-4627-89c8-2836919c8459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
